{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the UC Merced Land Use dataset archive from http://vision.ucmerced.edu/datasets/landuse.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "\n",
    "from skimage.transform import resize\n",
    "from skimage.external.tifffile import imread\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract image files from zipped, if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_dir = os.path.join('data', 'UCMerced_LandUse', 'Images')\n",
    "if not os.path.isdir(start_dir):\n",
    "    with ZipFile('UCMerced_LandUse.zip') as z:\n",
    "        z.extractall(path='data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get list of all TIFF image files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_labels = []\n",
    "image_names = []\n",
    "for class_name in os.listdir(start_dir):\n",
    "    path = os.path.join(start_dir, class_name)\n",
    "    files = os.listdir(path)\n",
    "    image_names.extend([os.path.join(path, file) for file in files])\n",
    "    image_labels.extend([class_name]*len(files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in all images from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array([imread(image_name) for image_name in image_names])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We're told these are 256x256x3 images. Let's check to be sure..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(247, 247, 3),\n",
       " (247, 256, 3),\n",
       " (249, 256, 3),\n",
       " (251, 256, 3),\n",
       " (253, 256, 3),\n",
       " (254, 256, 3),\n",
       " (255, 256, 3),\n",
       " (256, 242, 3),\n",
       " (256, 247, 3),\n",
       " (256, 249, 3),\n",
       " (256, 250, 3),\n",
       " (256, 252, 3),\n",
       " (256, 253, 3),\n",
       " (256, 254, 3),\n",
       " (256, 255, 3),\n",
       " (256, 256, 3),\n",
       " (257, 257, 3)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(image.shape for image in images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nope! Need to resize the images to the same shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 255)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check min and max pixel values before resizing\n",
    "np.min([np.min(image) for image in images]), np.max([np.max(image) for image in images])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note that skimage.transform.resize scales pixel values into range 0.0 - 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2100, 247, 247, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_shape = min(image.shape[:-1] for image in images)\n",
    "images = np.array([resize(image, new_shape, mode='constant') for image in images])\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm pixel values are rescaled [0.0 - 1.0] after resizing\n",
    "np.min([np.min(image) for image in images]), np.max([np.max(image) for image in images])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomly shuffle image list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_index = np.random.permutation(len(images))\n",
    "images = images[shuffle_index]\n",
    "labels = np.array(image_labels)[shuffle_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data intro train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1575, 247, 247, 3), (525, 247, 247, 3), (1575,), (525,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, stratify=labels)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
